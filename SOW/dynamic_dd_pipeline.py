#!/usr/bin/env python3
"""
Dynamic Due Diligence Pipeline
===============================
Unified system that handles any financial PDF (scanned or digital) and generates 
professional due diligence scope of work with everything LLM-generated.

Features:
- Automatic PDF type detection (scanned vs digital)
- Dynamic text extraction (OCR vs PyPDF2)
- LLM-based company name extraction
- Dynamic financial analysis and scope generation
- No hardcoded values - everything generated by LLM
"""

import os
import sys
import logging
from typing import Dict, Any, Optional
from pathlib import Path

from ocr_handler import OCRHandler
# Removed ABC-hardcoded system - now fully dynamic
from claude_integration import ClaudeFinancialAnalyzer

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class DynamicDueDiligencePipeline:
    """
    Complete pipeline for processing any financial PDF and generating due diligence scope
    """
    
    def __init__(self):
        self.ocr_handler = OCRHandler()
        self.claude_analyzer = ClaudeFinancialAnalyzer()
        self.version_file = "version_tracker.json"
        self.version_tracker = self._load_version_tracker()
    
    def _load_version_tracker(self) -> Dict[str, int]:
        """Load version tracker from file"""
        import json
        if os.path.exists(self.version_file):
            try:
                with open(self.version_file, "r") as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def _save_version_tracker(self):
        """Save version tracker to file"""
        import json
        try:
            with open(self.version_file, "w") as f:
                json.dump(self.version_tracker, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not save version tracker: {e}")
    
    def _save_versioned_output(self, company_name: str, content: str) -> str:
        """Save output with persistent version tracking"""
        # Clean company name for filename
        clean_name = company_name.replace(" ", "_").replace(".", "").replace(",", "")
        
        # Get current version number
        if clean_name not in self.version_tracker:
            self.version_tracker[clean_name] = 0
        
        self.version_tracker[clean_name] += 1
        version = self.version_tracker[clean_name]
        
        # Save updated version tracker
        self._save_version_tracker()
        
        # Create filename with version
        filename = f"{clean_name}_DD_SOW_v{version}.txt"
        
        # Save the file
        try:
            with open(filename, "w", encoding="utf-8") as f:
                f.write(content)
            
            print(f"📄 Scope saved as: {filename}")
            return filename
            
        except Exception as e:
            print(f"⚠️ Error saving file: {e}")
            return None

    def _save_extracted_text(self, extracted_text: str, extraction_method: str):
        """Save extracted text to single reusable file"""
        from datetime import datetime
        
        # Single consistent filename that gets overwritten
        filename = "extracted_text.txt"
        
        # Create header with extraction info
        header = f"""Extracted Text from PDF
Extraction Method: {extraction_method}
Extraction Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*50}

"""
        
        # Save the extracted text
        try:
            with open(filename, "w", encoding="utf-8") as f:
                f.write(header + extracted_text)
            
            print(f"📄 Extracted text saved to: {filename}")
            
        except Exception as e:
            print(f"⚠️ Error saving extracted text: {e}")
    
    def extract_company_name_from_text(self, extracted_text: str) -> str:
        """Extract company name using multiple methods with comprehensive fallbacks"""
        logger.info("🔍 Extracting company name from text...")
        
        # Method 1: Direct LLM extraction
        company_name = self.claude_analyzer.extract_company_name(extracted_text)
        
        if company_name and company_name.lower() not in ['unknown', 'not found', 'n/a', 'company', 'target company']:
            logger.info(f"✅ Company name found via LLM: {company_name}")
            return self._comprehensive_company_name_cleanup(company_name)
        
        # Method 2: Pattern matching for company suffixes
        import re
        company_patterns = [
            r'([A-Z][A-Za-z\s&]+(?:Private|Pvt|Public|Ltd|Limited|Inc|Corp|Corporation|Company|LLP|LLC)\.?\s*(?:Limited|Ltd)?)',
            r'(?:Company|Name|Entity)[\s:]+([A-Z][A-Za-z\s&]+)',
            r'(?:M/s|M/S|Messrs)\.?\s+([A-Z][A-Za-z\s&]+)',
        ]
        
        for pattern in company_patterns:
            matches = re.findall(pattern, extracted_text[:3000], re.MULTILINE)
            if matches:
                potential_name = matches[0] if isinstance(matches[0], str) else matches[0][0]
                cleaned_name = self._comprehensive_company_name_cleanup(potential_name)
                if cleaned_name and len(cleaned_name) > 3:
                    logger.info(f"✅ Company name found via pattern: {cleaned_name}")
                    return cleaned_name
        
        # Method 3: Look for common document headers
        header_lines = extracted_text[:1000].split('\n')[:10]
        for line in header_lines:
            line = line.strip()
            if len(line) > 5 and line[0].isupper() and not line.isupper():
                # Likely a company name
                cleaned_name = self._comprehensive_company_name_cleanup(line)
                if cleaned_name and len(cleaned_name) > 5:
                    logger.info(f"✅ Company name found in header: {cleaned_name}")
                    return cleaned_name
        
        # Method 4: Ask user directly if all else fails
        logger.warning("⚠️ Could not extract company name automatically")
        return self._get_company_name_from_user()
    
    def _comprehensive_company_name_cleanup(self, name: str) -> str:
        """Comprehensive cleanup while preserving legitimate company names"""
        if not name:
            return ""
        
        # Initial cleanup
        name = name.strip()
        
        # Remove common prefixes
        prefixes_to_remove = ['M/s', 'M/S', 'Messrs', 'Company:', 'Name:', 'Entity:']
        for prefix in prefixes_to_remove:
            if name.startswith(prefix):
                name = name[len(prefix):].strip()
        
        # Remove dates at the end (like "March 31, 2024")
        import re
        name = re.sub(r'\s*(January|February|March|April|May|June|July|August|September|October|November|December)\s+\d+,?\s*\d{4}$', '', name)
        name = re.sub(r'\s*\d{1,2}[-/]\d{1,2}[-/]\d{2,4}$', '', name)
        
        # Remove trailing periods but keep abbreviations
        if name.endswith('.') and not name.endswith(('Pvt.', 'Ltd.', 'Inc.')):
            name = name[:-1]
        
        # Remove any remaining special characters at the end
        name = name.rstrip('.,;:')
        
        # Final validation
        if len(name) < 3 or name.lower() in ['unknown', 'not found', 'n/a', 'company', 'target company', 'balance sheet']:
            return ""
        
        return name
    
    def _get_company_name_from_user(self) -> str:
        """Get company name from user input"""
        print("\n📝 Could not automatically extract company name from the document.")
        print("Please enter the company name:")
        
        while True:
            company_name = input("Company name: ").strip()
            if company_name and len(company_name) > 2:
                return company_name
            print("Please enter a valid company name (minimum 3 characters)")
    
    def analyze_financial_content_for_requirements(self, extracted_text: str, company_name: str) -> Dict[str, Any]:
        """
        Dynamic analysis of financial content to identify key requirements
        
        Args:
            extracted_text: The extracted text from PDF
            company_name: Name of the company
            
        Returns:
            Dict containing analysis results
        """
        logger.info(f"📊 Analyzing financial content for {company_name}...")
        
        # Use Claude to analyze the financial content dynamically
        analysis_prompt = f"""
        Analyze this financial document for {company_name} and identify:
        
        1. Financial periods covered (years/quarters)
        2. Key financial metrics present (revenue, EBITDA, etc.)
        3. Business type/industry indicators
        4. Any specific risk factors or concerns
        5. Document type (audited financials, management accounts, etc.)
        
        Be specific and extract actual numbers where available.
        
        Financial document text:
        {extracted_text[:4000]}
        """
        
        try:
            analysis_response = self.claude_analyzer.call_claude_api(
                analysis_prompt,
                max_tokens=1000
            )
            
            # Parse the analysis to structure requirements
            requirements = {
                'company_name': company_name,
                'has_revenue_data': 'revenue' in analysis_response.lower(),
                'has_balance_sheet': 'asset' in analysis_response.lower() or 'liability' in analysis_response.lower(),
                'has_cashflow': 'cash flow' in analysis_response.lower(),
                'industry_specific': self._identify_industry(analysis_response),
                'risk_areas': self._extract_risk_areas(analysis_response),
                'financial_periods': self._extract_periods(analysis_response)
            }
            
            logger.info(f"✅ Analysis complete for {company_name}")
            return requirements
            
        except Exception as e:
            logger.error(f"Error in financial analysis: {e}")
            # Return default requirements if analysis fails
            return {
                'company_name': company_name,
                'has_revenue_data': True,
                'has_balance_sheet': True,
                'has_cashflow': True,
                'industry_specific': 'general',
                'risk_areas': ['general business risks'],
                'financial_periods': 'historical period'
            }
    
    def _identify_industry(self, analysis_text: str) -> str:
        """Identify industry from analysis text"""
        industries = {
            'technology': ['software', 'technology', 'IT', 'digital'],
            'manufacturing': ['manufacturing', 'production', 'factory', 'goods'],
            'retail': ['retail', 'store', 'consumer', 'sales'],
            'services': ['service', 'consulting', 'professional'],
            'financial': ['financial', 'banking', 'investment'],
            'healthcare': ['healthcare', 'medical', 'pharma'],
            'construction': ['construction', 'building', 'real estate']
        }
        
        analysis_lower = analysis_text.lower()
        for industry, keywords in industries.items():
            if any(keyword in analysis_lower for keyword in keywords):
                return industry
        
        return 'general'
    
    def _extract_risk_areas(self, analysis_text: str) -> list:
        """Extract risk areas from analysis"""
        risk_keywords = [
            'debt', 'loss', 'decline', 'negative', 'concern',
            'risk', 'issue', 'problem', 'challenge', 'deficit'
        ]
        
        risks = []
        analysis_lower = analysis_text.lower()
        
        if any(keyword in analysis_lower for keyword in risk_keywords):
            if 'debt' in analysis_lower:
                risks.append('debt structure')
            if 'loss' in analysis_lower or 'negative' in analysis_lower:
                risks.append('profitability')
            if 'decline' in analysis_lower:
                risks.append('revenue trends')
            if 'cash' in analysis_lower and ('negative' in analysis_lower or 'concern' in analysis_lower):
                risks.append('cash flow')
        
        return risks if risks else ['general business risks']
    
    def _extract_periods(self, analysis_text: str) -> str:
        """Extract financial periods from analysis"""
        import re
        
        # Look for year patterns
        years = re.findall(r'20\d{2}', analysis_text)
        if years:
            unique_years = sorted(list(set(years)))
            if len(unique_years) > 1:
                return f"FY{unique_years[0]}-{unique_years[-1]}"
            else:
                return f"FY{unique_years[0]}"
        
        # Look for fiscal year patterns
        fy_pattern = re.findall(r'FY\s*\d{2,4}', analysis_text)
        if fy_pattern:
            return ', '.join(fy_pattern[:3])
        
        return "historical period"
    
    def _generate_strict_dd_scope(self, requirements: Dict[str, Any]) -> str:
        """
        Generate DD scope using optimized 4000 token prompt with proper formatting
        """
        company_name = requirements['company_name']
        
        logger.info(f"📝 Generating DD scope for {company_name}...")
        
        # Read the optimized prompt template
        # Try multiple locations for the prompt file
        prompt_locations = [
            "optimized_dd_prompt.txt",
            os.path.join(os.path.dirname(__file__), "optimized_dd_prompt.txt"),
            "/Users/adarshsingh/Desktop/NEW LLM ZEN/SOW LLM/optimized_dd_prompt.txt"
        ]
        
        base_prompt = None
        for prompt_file in prompt_locations:
            if os.path.exists(prompt_file):
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    base_prompt = f.read()
                break
        
        if not base_prompt:
            logger.error(f"Prompt file not found in any location")
            raise FileNotFoundError(f"Required prompt file missing: optimized_dd_prompt.txt")
        
        # Prepare the company-specific prompt with explicit formatting constraints
        final_prompt = f"""
Company Name: {company_name}
Industry Type: {requirements.get('industry_specific', 'general')}
Financial Periods: {requirements.get('financial_periods', 'historical period')}
Key Risk Areas: {', '.join(requirements.get('risk_areas', ['general']))}

CRITICAL FORMATTING REQUIREMENTS:
- Each procedure MUST be on its own numbered line (1., 2., 3., etc.)
- NO HTML tags like <br> are allowed
- Each table row must contain numbered procedures listed vertically
- Follow the EXACT table structure shown below

{base_prompt}

Now generate the DD scope for {company_name} following the EXACT format above. 
IMPORTANT: List procedures as separate numbered lines, NOT as <br> separated text within cells.
"""
        
        # Direct call with 4K tokens to get content
        raw_content = self._direct_llm_call_4k(final_prompt, company_name)
        
        # Post-process to fix any <br> tag issues
        raw_content = self._fix_table_formatting(raw_content)
        
        # Format with proper header
        return self._format_sow_with_header(company_name, raw_content, requirements)
    
    def _format_sow_with_header(self, company_name: str, content: str, requirements: Dict[str, Any]) -> str:
        """
        Format SOW content with proper header and metadata
        """
        from datetime import datetime
        
        # Get current date
        current_date = datetime.now().strftime("%B %d, %Y")
        
        # Extract financial periods
        financial_periods = requirements.get('financial_periods', 'FY2014-2025')
        
        # Count analysis areas (should be 14)
        analysis_areas = 14
        
        # Estimate complexity based on risk areas
        risk_areas = requirements.get('risk_areas', [])
        complexity = "High" if len(risk_areas) > 3 else "Medium" if len(risk_areas) > 1 else "Standard"
        
        # Estimate hours (standard for DD)
        estimated_hours = 350
        
        # Format the complete SOW
        formatted_sow = f"""FINANCIAL DUE DILIGENCE SCOPE OF WORK
==================================================
Company: {company_name}
Generated: {current_date}

📊 SCOPE SUMMARY
--------------------
Analysis Areas: {analysis_areas}
Estimated Hours: {estimated_hours}
Complexity Level: {complexity}

{content}"""
        
        return formatted_sow
    
    def _fix_table_formatting(self, content: str) -> str:
        """
        Post-process content to fix table formatting issues like <br> tags
        """
        import re
        
        # Pattern to find table cells with <br> tags
        br_pattern = r'(\| [^|]* \| )([^|]*<br>[^|]*)'
        
        def fix_cell_content(match):
            """Replace <br> tags with proper numbered lines"""
            prefix = match.group(1)  # The "| column |" part
            cell_content = match.group(2)  # The content with <br> tags
            
            # Split by <br> and clean up
            procedures = [p.strip() for p in cell_content.split('<br>') if p.strip()]
            
            # Format as numbered lines
            formatted_procedures = []
            for i, proc in enumerate(procedures, 1):
                # Remove existing numbering if present
                proc = re.sub(r'^\d+\.\s*', '', proc)
                formatted_procedures.append(f"{i}. {proc}")
            
            # Join with newlines
            return prefix + '\n'.join(formatted_procedures) + ' |'
        
        # Apply the fix
        fixed_content = re.sub(br_pattern, fix_cell_content, content)
        
        # Additional cleanup: ensure consistent spacing
        fixed_content = re.sub(r'<br>', '\n', fixed_content)
        
        return fixed_content
    
    def _direct_llm_call_4k(self, prompt: str, company_name: str) -> str:
        """Direct 4K token call for DD scope generation"""
        logger.info(f"🤖 Calling LLM for {company_name} with 4K tokens...")
        
        try:
            response = self.claude_analyzer.call_claude_api(
                prompt,
                max_tokens=4000
            )
            
            if response and len(response) > 500:
                logger.info(f"✅ Generated {len(response)} characters of DD scope")
                return response
            else:
                logger.error("Response too short or empty")
                raise ValueError("Insufficient response from LLM")
                
        except Exception as e:
            logger.error(f"Error in LLM call: {e}")
            raise
    
    def process_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """
        Main processing function - extracts text, analyzes, and generates DD scope
        Now returns structured data for API use
        """
        print(f"\n{'='*60}")
        print(f"🚀 STARTING DYNAMIC DD PIPELINE")
        print(f"{'='*60}\n")
        
        try:
            # Step 1: Extract text from PDF
            print("📄 Step 1: Extracting text from PDF...")
            extracted_text, extraction_method = self.ocr_handler.extract_text_from_pdf(pdf_path)
            
            if not extracted_text:
                raise ValueError("No text could be extracted from the PDF")
            
            print(f"✅ Extracted {len(extracted_text)} characters using {extraction_method}")
            
            # Save extracted text for reference
            self._save_extracted_text(extracted_text, extraction_method)
            
            # Step 2: Extract company name dynamically
            print("\n🏢 Step 2: Identifying company...")
            company_name = self.extract_company_name_from_text(extracted_text)
            print(f"✅ Company identified: {company_name}")
            
            # Step 3: Analyze financial content
            print("\n📊 Step 3: Analyzing financial content...")
            requirements = self.analyze_financial_content_for_requirements(extracted_text, company_name)
            print(f"✅ Analysis complete - Industry: {requirements['industry_specific']}")
            
            # Step 4: Generate DD scope
            print("\n📝 Step 4: Generating Due Diligence Scope...")
            dd_scope = self._generate_strict_dd_scope(requirements)
            
            # Step 5: Save output (optional for API)
            print("\n💾 Step 5: Saving output...")
            output_file = self._save_versioned_output(company_name, dd_scope)
            
            print(f"\n{'='*60}")
            print(f"✅ DD PIPELINE COMPLETE")
            print(f"{'='*60}\n")
            
            # Return structured data for API
            return {
                'success': True,
                'sow_content': dd_scope,
                'company_name': company_name,
                'financial_periods': requirements.get('financial_periods', 'historical period'),
                'extraction_method': extraction_method,
                'output_file': output_file,
                'metadata': {
                    'industry': requirements.get('industry_specific'),
                    'risk_areas': requirements.get('risk_areas'),
                    'text_length': len(extracted_text)
                }
            }
            
        except Exception as e:
            logger.error(f"Pipeline error: {e}")
            return {
                'success': False,
                'error': str(e),
                'sow_content': None,
                'company_name': None
            }

def main():
    """Main function to run the pipeline"""
    if len(sys.argv) != 2:
        print("Usage: python dynamic_dd_pipeline.py <path_to_pdf>")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    
    if not os.path.exists(pdf_path):
        print(f"Error: PDF file not found: {pdf_path}")
        sys.exit(1)
    
    pipeline = DynamicDueDiligencePipeline()
    result = pipeline.process_pdf(pdf_path)
    
    if not result['success']:
        print(f"\n❌ Pipeline failed: {result['error']}")
        sys.exit(1)

if __name__ == "__main__":
    main()